{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Amharic NER Data Labeling in CoNLL Format\n",
    "\n",
    "In this section, a subset of 30‚Äì50 messages was randomly sampled from the processed Amharic Telegram data. Each token in these messages was assigned an appropriate NER entity label (Product, Price, Location, etc.). The labeled data was then exported as a plain text file in CoNLL format for use in model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample message tokens: ['700', '2', '36373839', '·ä†·ãµ·à´·àª', '·ãµ·à¨·ã≥·ãã', '·ä†·à∏·ãã', '·àö·äì', '·àÖ·äï·çÉ', '1·äõ', '·çé·âÖ', '·àã·ã≠', '·ä•·äï·åà·äõ·àà·äï', '·ã®·â¥·àå·åç·à´·àù', '·âª·äì·àã·âΩ·äï·äï', '·ã≠·âÄ·àã·âÄ·àâ', '·ã®·â§·âµ', '·âÅ·å•·à≠', '109', '·ä•·äì', '110', '·â†', '2', '·ä†·ãã·à©·äï', '0987336458', '0948595409', '·ã≠·ã∞·ãç·àâ·àç·äï']\n",
      "Original text: adidas yeezy boost 700 v2\n",
      "Size 36#37#38#39\n",
      "MADE IN VIETNAM\n",
      "SHEWA BRAND\n",
      "·ä†·ãµ·à´·àª ·ãµ·à¨·ã≥·ãã ·ä†·à∏·ãã ·àö·äì ·àÖ·äï·çÉ 1·äõ ·çé·âÖ ·àã·ã≠ ·ä•·äï·åà·äõ·àà·äï \n",
      "·ã®·â¥·àå·åç·à´·àù ·âª·äì·àã·âΩ·äï·äï ·ã≠·âÄ·àã·âÄ·àâ\n",
      "üëáüëáüëá\n",
      "https://t.me//shewabrand\n",
      "https://t.me//shewabrand\n",
      "https://t.me//shewabrand\n",
      "https://t.me//shewabrand\n",
      "·ã®·â§·âµ ·âÅ·å•·à≠ 109 ·ä•·äì 110\n",
      "üì©·â† inbox¬† @shewat2 ·ä†·ãã·à©·äï\n",
      "\n",
      "üìû 0987336458\n",
      "üìû0948595409 ·ã≠·ã∞·ãç·àâ·àç·äï\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "# processed data directory\n",
    "processed_dir = \"../data/processed/text\"\n",
    "channels = [d for d in os.listdir(processed_dir) if os.path.isdir(os.path.join(processed_dir, d))]\n",
    "\n",
    "# Collect all message file paths\n",
    "all_files = []\n",
    "for channel in channels:\n",
    "    channel_dir = os.path.join(processed_dir, channel)\n",
    "    files = [os.path.join(channel_dir, f) for f in os.listdir(channel_dir) if f.endswith('.json')]\n",
    "    all_files.extend(files)\n",
    "\n",
    "# Randomly sample 40 messages\n",
    "sample_files = random.sample(all_files, 40)\n",
    "\n",
    "# Load the sampled messages\n",
    "sampled_msgs = []\n",
    "for file_path in sample_files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        msg = json.load(f)\n",
    "    sampled_msgs.append({'file': file_path, 'tokens': msg['tokens'], 'text': msg['text']})\n",
    "\n",
    "# Show the first message as an example\n",
    "print(\"Sample message tokens:\", sampled_msgs[0]['tokens'])\n",
    "print(\"Original text:\", sampled_msgs[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:  Token Labeling\n",
    "\n",
    "For each sampled message, entity labels were assigned to each token. The following entity types were used:\n",
    "- `B-Product`, `I-Product`\n",
    "- `B-LOC`, `I-LOC`\n",
    "- `B-PRICE`, `I-PRICE`\n",
    "- `O` (for tokens outside any entity)\n",
    "\n",
    "The code cell below was utilized to facilitate interactive labeling of each message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITY_LABELS = [\n",
    "    \"O\", \"B-Product\", \"I-Product\", \"B-LOC\", \"I-LOC\", \"B-PRICE\", \"I-PRICE\"\n",
    "]\n",
    "\n",
    "def label_message(tokens):\n",
    "    print(\"Tokens:\", tokens)\n",
    "    labels = []\n",
    "    for token in tokens:\n",
    "        label = input(f\"Label for '{token}': (O/B-Product/I-Product/B-LOC/I-LOC/B-PRICE/I-PRICE) \")\n",
    "        if label not in ENTITY_LABELS:\n",
    "            print(\"Invalid label, using 'O'.\")\n",
    "            label = \"O\"\n",
    "        labels.append(label)\n",
    "    return labels\n",
    "\n",
    "# Example: label the first sampled message\n",
    "labels = label_message(sampled_msgs[0]['tokens'])\n",
    "print(list(zip(sampled_msgs[0]['tokens'], labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Labeling All Sampled Messages\n",
    "\n",
    "The labeling process was repeated for all sampled messages. Tokens and their corresponding labels were stored in a list for subsequent export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data = []\n",
    "for i, msg in enumerate(sampled_msgs):\n",
    "    print(f\"\\nMessage {i+1}/{len(sampled_msgs)}\")\n",
    "    print(\"Original text:\", msg['text'])\n",
    "    print(\"Tokens:\", msg['tokens'])\n",
    "    labels = label_message(msg['tokens'])\n",
    "    labeled_data.append({'tokens': msg['tokens'], 'labels': labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Exporting Labeled Data to CoNLL Format\n",
    "\n",
    "Upon completion of labeling, the data was exported as a plain text file in CoNLL format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_conll(labeled_data, output_path):\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for item in labeled_data:\n",
    "            for token, label in zip(item['tokens'], item['labels']):\n",
    "                f.write(f\"{token} {label}\\n\")\n",
    "            f.write(\"\\n\")  \n",
    "\n",
    "output_path = \"../data/labeled/ner_labeled_sample.conll\"\n",
    "save_to_conll(labeled_data, output_path)\n",
    "print(f\"Saved labeled data to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
